{"cells":[{"cell_type":"markdown","metadata":{"id":"nNnGK00hzMPH"},"source":["# 简介"]},{"cell_type":"markdown","metadata":{"id":"TdDTfSyhzcmC"},"source":["在这个Notebook里面，我将尝试利用现有技术实现一个基于Transformer的入侵检测系统并尽可能对其进行改进。首先，我将描述本架构的各个组成部分，在阐明其原理后对模型进行训练与评估，并在最后在相同问题下将该架构与其他架构进行对比。\n","\n","以下是为训练此模型而导入的包："]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":86529,"status":"ok","timestamp":1715355366585,"user":{"displayName":"Seventhree","userId":"06810280268935198942"},"user_tz":-480},"id":"Hgk3u3QaGR1w","outputId":"096eea8c-aaae-4153-ea9d-0cef0635c7be"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting einops\n","  Downloading einops-0.8.0-py3-none-any.whl (43 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/43.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: einops\n","Successfully installed einops-0.8.0\n","Collecting rtdl_num_embeddings\n","  Downloading rtdl_num_embeddings-0.0.9-py3-none-any.whl (11 kB)\n","Requirement already satisfied: torch<3,>=1.8 in /usr/local/lib/python3.10/dist-packages (from rtdl_num_embeddings) (2.2.1+cu121)\n","Collecting rtdl_revisiting_models>=0.0.2 (from rtdl_num_embeddings)\n","  Downloading rtdl_revisiting_models-0.0.2-py3-none-any.whl (12 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<3,>=1.8->rtdl_num_embeddings) (3.14.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=1.8->rtdl_num_embeddings) (4.11.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<3,>=1.8->rtdl_num_embeddings) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<3,>=1.8->rtdl_num_embeddings) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=1.8->rtdl_num_embeddings) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch<3,>=1.8->rtdl_num_embeddings) (2023.6.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch<3,>=1.8->rtdl_num_embeddings)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch<3,>=1.8->rtdl_num_embeddings)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch<3,>=1.8->rtdl_num_embeddings)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch<3,>=1.8->rtdl_num_embeddings)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch<3,>=1.8->rtdl_num_embeddings)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch<3,>=1.8->rtdl_num_embeddings)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch<3,>=1.8->rtdl_num_embeddings)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch<3,>=1.8->rtdl_num_embeddings)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch<3,>=1.8->rtdl_num_embeddings)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.19.3 (from torch<3,>=1.8->rtdl_num_embeddings)\n","  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch<3,>=1.8->rtdl_num_embeddings)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=1.8->rtdl_num_embeddings) (2.2.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch<3,>=1.8->rtdl_num_embeddings)\n","  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<3,>=1.8->rtdl_num_embeddings) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<3,>=1.8->rtdl_num_embeddings) (1.3.0)\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, rtdl_revisiting_models, rtdl_num_embeddings\n","Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 rtdl_num_embeddings-0.0.9 rtdl_revisiting_models-0.0.2\n"]}],"source":["!pip install einops\n","# !pip install numpy\n","# !pip install pandas\n","# !pip install scikit-learn\n","# !pip install imbalanced-learn\n","!pip install rtdl_num_embeddings"]},{"cell_type":"markdown","metadata":{"id":"WQi0ZLpyRpxu"},"source":["以下代码用于挂载google drive"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29419,"status":"ok","timestamp":1715355395992,"user":{"displayName":"Seventhree","userId":"06810280268935198942"},"user_tz":-480},"id":"ogLQXNu5RxYQ","outputId":"1073138e-9de1-4527-a10b-f42b5b77a0ca"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"O9tBNq4k6B0L"},"source":["# 结构"]},{"cell_type":"markdown","metadata":{"id":"dpbc5i3s6ODr"},"source":["## 嵌入(Embedding)"]},{"cell_type":"markdown","metadata":{"id":"YBQYPZ7u6T3a"},"source":["在该部分里，数值信息将被转换为可被Transformer识别的特征值并提供给后面的结构进行学习。"]},{"cell_type":"markdown","metadata":{"id":"AKXbzP30kOED"},"source":["$$ReLU(Linear(Periodic(x_i)))$$"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":532,"status":"ok","timestamp":1715355472193,"user":{"displayName":"Seventhree","userId":"06810280268935198942"},"user_tz":-480},"id":"sIPm68LQ8iiT"},"outputs":[],"source":["from torch import nn\n","import torch\n","from einops import rearrange\n","from rtdl_num_embeddings import PeriodicEmbeddings\n","\n","class Embedder(nn.Module):\n","    def __init__(self, dim, num_numerical_types=10):\n","        super().__init__()\n","        # self.weights = nn.Parameter(torch.randn(num_numerical_types, dim))\n","        # self.biases = nn.Parameter(torch.randn(num_numerical_types, dim))\n","        self.embeddings = PeriodicEmbeddings(num_numerical_types, dim, lite=False)\n","\n","    def forward(self, x):\n","        # x = rearrange(x, 'b n -> b n 1')\n","        # return x * self.weights + self.biases\n","        return self.embeddings(x)\n"]},{"cell_type":"markdown","metadata":{"id":"8IH0RsbBkK5I"},"source":["## 位置编码(Positional Encoding)"]},{"cell_type":"markdown","metadata":{"id":"Nf4ErG_gkyb_"},"source":["由于嵌入产生的信息并不带有位置信息，故需要在学习前将位置信息写入训练数据中。"]},{"cell_type":"markdown","metadata":{"id":"BYa6t4yQnmqN"},"source":["$$PE(pos, 2i) = \\sin(pos/1000^{2i/d\\_model})$$\n","$$PE(pos, 2i+1) = \\cos(pos/1000^{2i/d\\_model})$$"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1715355400561,"user":{"displayName":"Seventhree","userId":"06810280268935198942"},"user_tz":-480},"id":"QPnc3zj8nqbp"},"outputs":[],"source":["import torch\n","from torch import nn\n","from torch.autograd import Variable\n","from math import cos, sin, sqrt\n","\n","class Positional_Encoder(nn.Module):\n","    def __init__(self, d_model, max_seq_len = 10):\n","        super().__init__()\n","        self.d_model = d_model\n","\n","        pe = torch.zeros(max_seq_len, d_model)\n","        for pos in range(max_seq_len):\n","            for i in range(0,d_model,2):\n","                pe[pos,i] = sin(pos / (1000**(i/d_model)))\n","                pe[pos,i+1] = cos(pos / (1000**(i/d_model)))\n","\n","        pe = pe.unsqueeze(0)\n","        self.register_buffer(\"pe\",pe)\n","\n","    def forward(self, x):\n","        x = x * sqrt(self.d_model)\n","        seq_len = x.size(1)\n","        y = Variable(self.pe[:,:seq_len],requires_grad=False).cuda()\n","        x = x + y\n","        return x"]},{"cell_type":"markdown","metadata":{"id":"JnqY-Q7en1jI"},"source":["## 注意力机制(Attention)"]},{"cell_type":"markdown","metadata":{"id":"4x1Clko8oK4g"},"source":["本部分用于对输入向量进行处理以获取输入与输出间的对应关系。具体计算过程如下："]},{"cell_type":"markdown","metadata":{"id":"2U4rFViWoMPy"},"source":["$$Attention(Q,K,V) = softmax\\left(M+\\frac{QK^T}{\\sqrt{d_k}}\\right)$$"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1715355400561,"user":{"displayName":"Seventhree","userId":"06810280268935198942"},"user_tz":-480},"id":"CPYaAH59oTj-"},"outputs":[],"source":["import torch\n","from torch import nn\n","from torch.nn import functional as F\n","import math\n","\n","def attention(q, k, v, d_k, mask=None, dropout=None):\n","    scores = torch.matmul(q, k.transpose(-2, -1)) /  math.sqrt(d_k)\n","    if mask is not None:\n","        scores = scores.masked_fill(mask == 0, -1e9)\n","    scores = F.softmax(scores, dim=-1)\n","\n","    if dropout is not None:\n","        scores = dropout(scores)\n","\n","    output = torch.matmul(scores, v)\n","    return output\n","\n","class Multi_Head_Attention(nn.Module):\n","    def __init__(self, heads, d_model, dropout):\n","        super().__init__()\n","        self.d_model = d_model\n","        self.d_k = d_model // heads\n","        self.h = heads\n","\n","        self.q_linear = nn.Linear(d_model, d_model)\n","        self.v_linear = nn.Linear(d_model, d_model)\n","        self.k_linear = nn.Linear(d_model, d_model)\n","        self.dropout = nn.Dropout(dropout)\n","        self.out = nn.Linear(d_model, d_model)\n","\n","    def forward(self, q, k, v, mask=None):\n","\n","        bs = q.size(0)\n","\n","        # perform linear operation and split into h heads\n","        k = self.k_linear(k).view(bs, -1, self.h, self.d_k)\n","        q = self.q_linear(q).view(bs, -1, self.h, self.d_k)\n","        v = self.v_linear(v).view(bs, -1, self.h, self.d_k)\n","\n","        # transpose to get dimensions bs * h * sl * d_model\n","        k = k.transpose(1,2)\n","        q = q.transpose(1,2)\n","        v = v.transpose(1,2)\n","\n","        scores = attention(q, k, v, self.d_k, mask, self.dropout)\n","\n","        # concatenate heads and put through final linear layer\n","        concat = scores.transpose(1,2).contiguous().view(bs, -1, self.d_model)\n","\n","        output = self.out(concat)\n","        return output\n"]},{"cell_type":"markdown","metadata":{"id":"DDdttxGBejsR"},"source":["## 掩蔽(Masks)"]},{"cell_type":"markdown","metadata":{"id":"pa9RVFRufU_T"},"source":["该部分用于对输入解码器(Decoder)的向量进行掩蔽来使得解码器能够根据上下文来推算结果。"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1715355400561,"user":{"displayName":"Seventhree","userId":"06810280268935198942"},"user_tz":-480},"id":"GVhnYainfUSo"},"outputs":[],"source":["import numpy as np\n","import torch\n","from torch.autograd import Variable\n","\n","def get_mask(batch_size, heads, seq_size):\n","    mask_prob = 0.2\n","    mask = torch.rand((batch_size, heads, seq_size, seq_size)) > mask_prob\n","    return mask.cuda()"]},{"cell_type":"markdown","metadata":{"id":"3d4tpIRUiXpe"},"source":["## 前馈网络(Feed-Forward Network)"]},{"cell_type":"markdown","metadata":{"id":"eTW1sRE6ijFy"},"source":["该部分主要用于记忆注意力机制计算所产生的的关系。具体原理如下："]},{"cell_type":"markdown","metadata":{"id":"-0mGUiJviuBc"},"source":["$$FFN(x) = \\max(0,xW_1 + b_1)W_2 + b_2$$"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1715355400562,"user":{"displayName":"Seventhree","userId":"06810280268935198942"},"user_tz":-480},"id":"_WtVjTp2iw-Z"},"outputs":[],"source":["from torch import nn\n","from torch.nn import functional as F\n","\n","class FeedForward(nn.Module):\n","    def __init__(self, d_model, d_ff=1024, dropout = 0.1):\n","        super().__init__()\n","        self.linear_1 = nn.Linear(d_model, d_ff)\n","        self.dropout = nn.Dropout(dropout)\n","        self.linear_2 = nn.Linear(d_ff, d_model)\n","    def forward(self, x):\n","        x = self.dropout(F.relu(self.linear_1(x)))\n","        x = self.linear_2(x)\n","        return x"]},{"cell_type":"markdown","metadata":{"id":"ez3GmV8qlEoz"},"source":["## 层归一化(Layer Norm)"]},{"cell_type":"markdown","metadata":{"id":"pf8abbIElJZp"},"source":["主要用于使不同范围的数据归一化到[0, 1]区间内，方便模型进行处理，具体原理如下："]},{"cell_type":"markdown","metadata":{"id":"XbJUS2bqlcKy"},"source":["$$LN(x) = \\frac{x - \\mu}{\\delta}\\cdot \\alpha + \\beta$$"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1715355400562,"user":{"displayName":"Seventhree","userId":"06810280268935198942"},"user_tz":-480},"id":"CrBAIucglfQw"},"outputs":[],"source":["from torch import nn\n","import torch\n","\n","class Norm(nn.Module):\n","    def __init__(self, d_model, eps = 1e-6):\n","        super().__init__()\n","\n","        self.size = d_model\n","\n","        self.alpha = nn.Parameter(torch.ones(self.size))\n","        self.bias = nn.Parameter(torch.zeros(self.size))\n","        self.eps = eps\n","    def forward(self, x):\n","        norm = self.alpha * (x - x.mean(dim=-1, keepdim=True)) \\\n","        / (x.std(dim=-1, keepdim=True) + self.eps) + self.bias\n","        return norm"]},{"cell_type":"markdown","metadata":{"id":"BxD3yhUnYwG_"},"source":["## 编码器(Encoder)"]},{"cell_type":"markdown","metadata":{"id":"UKUKjwm0i2BI"},"source":["整个编码器由数个编码器嵌入器、数个编码器层与层归一化层组成。其中，一个编码器层由层归一化、注意力机制与前馈神经网络层组成，数据在经过这些处理后由dropout方法进行输出。"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1715355400562,"user":{"displayName":"Seventhree","userId":"06810280268935198942"},"user_tz":-480},"id":"JkFCQue0Yvob"},"outputs":[],"source":["from torch import nn\n","import copy\n","\n","def get_clones(module, N):\n","    return nn.ModuleList([copy.deepcopy(module) for i in range(N)])\n","\n","class Encoder_Layer(nn.Module):\n","    def __init__(self, d_model, heads, dropout = 0.1):\n","        super().__init__()\n","        self.norm_1 = Norm(d_model)\n","        self.norm_2 = Norm(d_model)\n","        self.attn = Multi_Head_Attention(heads, d_model, dropout)\n","        self.feedf = FeedForward(d_model).cuda()\n","        self.dropout_1 = nn.Dropout(dropout).cuda()\n","        self.dropout_2 = nn.Dropout(dropout).cuda()\n","\n","    def forward(self, x, mask):\n","        x2 = self.norm_1(x)\n","        x = x + self.dropout_1(self.attn(x2,x2,x2,mask))\n","        x2 = self.norm_2(x)\n","        x = x + self.dropout_2(self.feedf(x2))\n","        return x\n","\n","class Encoder(nn.Module):\n","    def __init__(self, d_model, N, heads, dropout = 0.1):\n","        super().__init__()\n","        self.N = N\n","        self.embed = Embedder(d_model)\n","        self.pe = Positional_Encoder(d_model)\n","        self.layers = get_clones(Encoder_Layer(d_model, heads, dropout), N)\n","        self.norm = Norm(d_model)\n","\n","    def forward(self, src, mask = None):\n","        x = self.embed(src)\n","        x = self.pe(x)\n","        for i in range(self.N):\n","            x = self.layers[i](x,mask)\n","        return self.norm(x)"]},{"cell_type":"markdown","metadata":{"id":"Q-OdE8wWZJjO"},"source":["## 解码器"]},{"cell_type":"markdown","metadata":{"id":"2tOp7UHV0T10"},"source":[]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1715355400562,"user":{"displayName":"Seventhree","userId":"06810280268935198942"},"user_tz":-480},"id":"9pA9SiVx0BFB"},"outputs":[],"source":["import torch\n","from torch import nn\n","import copy\n","\n","def get_clones(module, N):\n","    return nn.ModuleList([copy.deepcopy(module) for i in range(N)])\n","\n","class Decoder_Layer(nn.Module):\n","    def __init__(self, d_model, heads, dropout = 0.1):\n","        super().__init__()\n","        self.norm_1 = Norm(d_model)\n","        self.norm_2 = Norm(d_model)\n","        self.norm_3 = Norm(d_model)\n","        self.attn = Multi_Head_Attention(heads, d_model, dropout)\n","        self.msk_attn = Multi_Head_Attention(heads, d_model, dropout)\n","        self.feedf = FeedForward(d_model).cuda()\n","        self.dropout_1 = nn.Dropout(dropout).cuda()\n","        self.dropout_2 = nn.Dropout(dropout).cuda()\n","        self.dropout_3 = nn.Dropout(dropout).cuda()\n","\n","    def forward(self, x, e_outputs, mask):\n","        x2 = self.norm_1(x)\n","        x = x + self.dropout_1(self.msk_attn(x2,x2,x2,mask))\n","        x2 = self.norm_2(x)\n","        x = x + self.dropout_2(self.attn(x2,e_outputs,e_outputs,mask=None))\n","        x2 = self.norm_3(x)\n","        x = x +self.dropout_3(self.feedf(x2))\n","        return x\n","\n","class Decoder(nn.Module):\n","    def __init__(self, d_model, N, heads, dropout = 0.1):\n","        super().__init__()\n","        self.N = N\n","        self.embed = Embedder(d_model)\n","        self.pe = Positional_Encoder(d_model,1)\n","        self.layers = get_clones(Decoder_Layer(d_model, heads, dropout), N)\n","        self.norm = Norm(d_model)\n","\n","    def forward(self, trg, e_outputs, mask = None):\n","        x = self.embed(trg)\n","        x = self.pe(x)\n","        for i in range(self.N):\n","            x = self.layers[i](x,e_outputs,mask)\n","        return self.norm(x)\n"]},{"cell_type":"markdown","metadata":{"id":"LH1P_Gj4ZNxo"},"source":["## 整体架构定义"]},{"cell_type":"markdown","metadata":{"id":"S47cD2sk0Uoa"},"source":[]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1715355400562,"user":{"displayName":"Seventhree","userId":"06810280268935198942"},"user_tz":-480},"id":"zEg0bhTe0VD2"},"outputs":[],"source":["import torch\n","from torch import nn\n","\n","class Transformer(nn.Module):\n","    def __init__(self, trg_vocab, d_model, N, heads, dropout = 0.1):\n","        super().__init__()\n","        self.encoder = Encoder(d_model, N , heads, dropout)\n","        self.decoder = Decoder(d_model, N , heads, dropout)\n","        self.out = nn.Linear(10*d_model, trg_vocab)\n","\n","    def forward(self, src, trg_mask=None):\n","        e_outputs = self.encoder(src, None)\n","        d_output = self.decoder(src, e_outputs, trg_mask)\n","        d_intermediate = d_output.view(d_output.size(0), -1)\n","        output = self.out(d_intermediate)\n","        output = torch.softmax(output,dim=1)\n","        return output"]},{"cell_type":"markdown","metadata":{"id":"2TdXPFHO1zPv"},"source":["# 数据集与数据处理"]},{"cell_type":"markdown","metadata":{"id":"BoE5dRpO1-PU"},"source":["## NF-UNSW-NB15-v2\n","下载数据集:https://rdm.uq.edu.au/files/8c6e2a00-ef9c-11ed-827d-e762de186848\n","\n","UNSW-NB15数据集的基于NetFlow的格式，命名为NF-UNSW-NB15，已经通过添加额外的NetFlow特征进行了扩展，并标记了其相应的攻击类别。数据流的总数为2,390,275，其中95,053（3.98%）是攻击样本，2,295,222（96.02%）是良性样本。"]},{"cell_type":"markdown","metadata":{"id":"uDLur9Kj2E4o"},"source":["## 数据处理\n","本部分用于对数据进行预处理。由于本数据集的特殊性——正常流量远多于异常攻击流量，因此需要对数据进行下采样与ADASYN处理，前者用于限制数量较多的样本的数量，后者用于对数量较少的样本进行插值处理以增加其数量。"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":775,"status":"ok","timestamp":1715355401333,"user":{"displayName":"Seventhree","userId":"06810280268935198942"},"user_tz":-480},"id":"Y_u4bTpXFOr1"},"outputs":[],"source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","import numpy as np\n","from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n","from sklearn.neighbors import NearestNeighbors\n","from sklearn.utils import shuffle\n","from imblearn.over_sampling import SMOTE\n","from imblearn.under_sampling import RandomUnderSampler\n","from sklearn.decomposition import PCA\n","from sklearn.preprocessing import StandardScaler\n","import os\n","\n","label_mapping = {}\n","directory_path = 'drive/MyDrive/Colab Notebooks/NF-UNSW-NB15-v2/data/'\n","\n","\n","class UNSWDataset(Dataset):\n","    def __init__(self, data):\n","        self.features = data[:, :-3]  # Feature Columns\n","        self.at_type = data[:, -3]  # Attack Type Column\n","        self.labels = data[:, -2:]  # 1 Hot Encoded Label\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def __getitem__(self, idx):\n","        feature = torch.from_numpy(self.features[idx]).float()\n","        label = self.labels[idx]\n","        at_type = self.at_type[idx]\n","\n","        return feature, label, at_type\n","\n","def load_data():\n","    if os.path.exists(directory_path + \"preprocessed/data.csv.gz\"):\n","        print(\"Loading Preprocessed Data\")\n","        data = pd.read_csv(directory_path + 'preprocessed/data.csv.gz', compression='gzip')\n","\n","    else:\n","        chunk_size = 100000\n","        chunks = pd.read_csv(directory_path + 'NF-UNSW-NB15-v2.csv', chunksize=chunk_size)\n","        max_float64 = np.finfo(np.float64).max\n","\n","        dataframes = []\n","        for chunk in chunks:\n","            chunk.drop(chunk.columns[[0, 2]], axis=1, inplace=True)\n","            chunk.rename(columns={'Attack': 'Attack_type'}, inplace=True)\n","            chunk.columns = chunk.columns.str.strip()\n","            chunk = chunk.dropna()\n","\n","            feature_chunk = chunk.drop(columns=['Label', 'Attack_type'])\n","            numeric_columns = feature_chunk.select_dtypes(include=[np.number]).columns\n","            feature_chunk[numeric_columns] = np.minimum(feature_chunk[numeric_columns], max_float64)\n","            labels_chunk = chunk[['Label', 'Attack_type']]\n","            chunk = pd.concat([feature_chunk, labels_chunk], axis=1)\n","            dataframes.append(chunk)\n","        data = pd.concat(dataframes, ignore_index=True)\n","\n","        label_counts = data['Attack_type'].value_counts()\n","        print(label_counts)\n","\n","        # data = data.dropna()\n","\n","        # features = data.drop(columns=['Label', 'Attack'])\n","        # features = features.where(features <= max_float64, max_float64)\n","        # labels = data['Label']\n","        # data = pd.concat([features, labels], axis=1)\n","\n","        # Undersampling & SMOTE\n","\n","        max_class_size = 100000  # Size of all Classes for Undersampling\n","        class_counts = data['Attack_type'].value_counts()\n","        classes_to_undersample = class_counts[class_counts > max_class_size].index\n","\n","        under_sampler = RandomUnderSampler(sampling_strategy={\n","            label: 7 * max_class_size if label == \"Benign\" else max_class_size if label in classes_to_undersample else\n","            class_counts[label] for label in np.unique(data['Attack_type'])\n","        }, random_state=42)\n","        nn_estimator = NearestNeighbors(n_neighbors=5, n_jobs=-1)\n","        smote = SMOTE(sampling_strategy={\n","            label: 7 * max_class_size if label == \"Benign\" else max_class_size for label in np.unique(data['Attack_type'])\n","        }, k_neighbors=nn_estimator, random_state=42)\n","        scaler = MinMaxScaler()\n","\n","        features = data.drop(columns=['Label', 'Attack_type'])\n","        labels = data['Attack_type']\n","        sampled_features, sampled_labels = under_sampler.fit_resample(features, labels)\n","        balanced_features, balanced_labels = smote.fit_resample(sampled_features, sampled_labels)\n","        scaled_data = scaler.fit_transform(balanced_features)\n","\n","        data = pd.DataFrame(data=scaled_data, columns=features.columns)\n","\n","        # Encode the actual Attack type for later analysis\n","        label_encoder = LabelEncoder()\n","        data['Attack_type'] = label_encoder.fit_transform(balanced_labels)\n","        label_mapping = dict(enumerate(label_encoder.classes_))\n","\n","        # 1 Hot Encoding\n","        data['Attack_Label'] = data['Attack_type'].apply(lambda x: \"Attack\" if label_mapping[x] != \"Benign\" else \"Benign\")\n","        encoded_labels = pd.get_dummies(data['Attack_Label'], prefix='', prefix_sep='')\n","        data = pd.concat([data, encoded_labels], axis=1)\n","        data.drop(\"Attack_Label\", axis=1, inplace=True)\n","\n","        features = data.drop(columns=['Attack_type', 'Attack', 'Benign'])\n","        labels = data[['Attack_type', 'Attack', 'Benign']]\n","\n","        # PCA features extraction\n","        print('Using PCA...')\n","        scaler = StandardScaler()\n","        features = np.nan_to_num(scaler.fit_transform(features))\n","        pca = PCA(n_components=10, svd_solver='randomized')\n","        features = pd.DataFrame(pca.fit_transform(features))\n","        data = pd.concat([features, labels], axis=1)\n","\n","        label_counts = data['Attack_type'].value_counts()\n","        print(label_counts)\n","        if not os.path.exists(directory_path + 'preprocessed'):\n","            os.makedirs(directory_path + 'preprocessed')\n","        data.to_csv(directory_path + 'preprocessed/data.csv.gz', index=False, compression='gzip')\n","        print(\"saved\")\n","\n","    train_data, val_data = train_test_split(data, test_size=0.2, random_state=42)\n","    train_data, val_data = train_data.values, val_data.values\n","\n","    return train_data, val_data\n","\n","\n","def get_data_loader(data, batch_size):\n","    unsw_dataset = UNSWDataset(data)\n","\n","    return DataLoader(unsw_dataset, batch_size=batch_size, shuffle=True)\n"]},{"cell_type":"markdown","metadata":{"id":"yiFmfZhu2NCN"},"source":["# 模型训练"]},{"cell_type":"markdown","metadata":{"id":"lKUDlHn8FVzo"},"source":["定义训练与评估函数"]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":843,"status":"ok","timestamp":1715357394458,"user":{"displayName":"Seventhree","userId":"06810280268935198942"},"user_tz":-480},"id":"LZAdZpC_FVQl"},"outputs":[],"source":["import torch\n","from torch import nn\n","from torch.nn import functional as F\n","import numpy as np\n","import time\n","import os\n","import torch\n","from torch.nn import functional as F\n","from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, r2_score, \\\n","    mean_squared_error, log_loss\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from torch.optim.lr_scheduler import StepLR\n","from sklearn.metrics import ConfusionMatrixDisplay\n","\n","\n","def plot_metrics(losses, accs, pres, recs, aucs, f1s):\n","    epochs = range(1, len(losses) + 1)\n","    metrics = {'Loss': losses, 'Accuracy': accs, 'Precision': pres, 'Recall': recs, 'AUC': aucs, 'F1 Score': f1s}\n","    categories = list(metrics.keys())\n","    num_categories = len(categories)\n","    num_subplots_per_row = 3\n","    num_rows = (num_categories + num_subplots_per_row - 1) // num_subplots_per_row\n","\n","    plt.figure(figsize=(16, 4 * num_rows))  # 调整图表大小以适应多子图\n","\n","    for i, metric_name in enumerate(categories, start=1):\n","        plt.subplot(num_rows, num_subplots_per_row, i)\n","        plt.plot(epochs, metrics[metric_name], marker='o')\n","        plt.title(metric_name)\n","        plt.xlabel('Epoch')\n","        plt.ylabel(metric_name.replace(\" \", \"\\n\"))  # 分行显示标签，如果标签中有空格的话\n","        plt.grid(True)\n","\n","    plt.tight_layout(rect=[0, 0.03, 1, 0.95])  # 自动调整子图间距，留出顶部标题空间\n","    plt.show()\n","\n","\n","def eval_model(model, loader):\n","    model.cuda()\n","    model.eval()\n","    losses = []\n","    correct = 0\n","    predictions = []\n","    targets = []\n","\n","    with torch.no_grad():\n","        for data, target, _ in loader:\n","            data, target = data.to(\"cuda\"), target.to(\"cuda\")\n","            output = model(data)\n","            loss = F.cross_entropy(output, target).item()\n","            losses.append(loss)\n","            pred = torch.argmax(output, dim=1)\n","            correct += torch.eq(torch.argmax(output, dim=1),torch.argmax(target, dim=1)).cpu().sum().item()\n","            predictions.extend(pred.cpu().numpy())\n","            targets.extend(target.cpu().numpy())\n","\n","    eval_loss = np.mean(losses)\n","    eval_acc = correct / len(loader.dataset)\n","    targets = torch.tensor(targets)\n","\n","    # 计算精确率、召回率、F1 分数\n","    precision = precision_score(torch.argmax(targets, dim=1), predictions, average='macro')\n","    recall = recall_score(torch.argmax(targets, dim=1), predictions, average='macro')\n","    f1 = f1_score(torch.argmax(targets, dim=1), predictions, average='macro')\n","\n","    # 计算 ROC 曲线和 AUC\n","    try:\n","        auc = roc_auc_score(torch.argmax(targets, dim=1), predictions, average='weighted')\n","    except ValueError:\n","        auc = None\n","\n","    # 计算混淆矩阵\n","    conf_matrix = confusion_matrix(torch.argmax(targets, dim=1), predictions)\n","\n","    # 计算 R-squared\n","    r_squared = r2_score(torch.argmax(targets, dim=1), predictions)\n","\n","    # 计算均方误差\n","    mse = mean_squared_error(torch.argmax(targets, dim=1), predictions)\n","\n","    # 计算对数损失\n","    try:\n","        logloss = log_loss(torch.argmax(targets, dim=1), predictions)\n","    except ValueError:\n","        logloss = None\n","\n","    print(\"Loss:\", eval_loss, \"Accuracy:\", eval_acc)\n","    print(\"Precision:\", precision, \"Recall:\", recall, \"F1 Score:\", f1)\n","    print(\"AUC:\", auc)\n","    print(\"Confusion Matrix:\")\n","    print(conf_matrix)\n","    print(\"R-squared:\", r_squared)\n","    print(\"Mean Squared Error:\", mse)\n","    print(\"Log Loss:\", logloss)\n","\n","    return eval_loss, eval_acc, precision, recall, f1, auc, r_squared, mse, logloss, conf_matrix\n","\n","\n","def train_model(model, opt, epochs, data, eval_data, path, print_every=100):\n","    model.cuda()\n","\n","    pretrained_path = \"drive/MyDrive/Colab Notebooks/NF-UNSW-NB15-v2/pretrained\"\n","    top_acc = 0.\n","    scheduler = StepLR(opt, step_size=1, gamma=0.9)\n","\n","    if os.path.exists(pretrained_path + \"/\" + path):\n","        print(\"Loading Pretrained Model\")\n","        state = torch.load(pretrained_path + \"/\" + path)\n","        model.load_state_dict(state[\"model_state_dict\"])\n","        start_epoch = state[\"epoch\"] + 1\n","        losses = state[\"ep_loss\"]\n","        accs = state[\"ep_acc\"]\n","        top_acc = max(accs)\n","        aucs = state[\"aucs\"]\n","        f1s = state['f1s']\n","        recs = state['recs']\n","        pres = state['pres']\n","        conf_matrix = state['conf_matrix']\n","    else:\n","        start_epoch = 0\n","        losses, accs = [], []\n","        aucs = []\n","        f1s = []\n","        recs = []\n","        pres = []\n","        try:\n","            os.mkdir(pretrained_path)\n","        except OSError as error:\n","            pass\n","\n","    start = time.time()\n","    temp = start\n","\n","    for epoch in range(start_epoch, epochs):\n","        model.train()\n","        total_loss = 0\n","        for i, batch in enumerate(data):\n","            src, trg, _ = batch\n","            src, trg = src.cuda(), trg.cuda()\n","\n","            if isinstance(model, Transformer):\n","                trg_mask = get_mask(128, 8, 10)\n","            else:\n","                trg_mask = None\n","\n","            preds = model(src, trg_mask)\n","            opt.zero_grad()\n","            loss = F.cross_entropy(preds, trg)\n","            loss.backward()\n","            opt.step()\n","            scheduler.step()\n","\n","            total_loss += loss.data\n","            if (i + 1) % print_every == 0:\n","                loss_avg = total_loss / print_every\n","                print(\"time = %dm, epoch %d, iter = %d, loss = %.3f, \\\n","                %ds per %d iters\" % ((time.time() - start) // 60,\n","                                     epoch + 1, i + 1, loss_avg, time.time() - temp,\n","                                     print_every))\n","                total_loss = 0\n","                temp = time.time()\n","        eval_loss, eval_acc, precision, recall, f1, auc, r_squared, mse, logloss, conf_matrix = eval_model(model, eval_data)\n","        losses.append(eval_loss)\n","        accs.append(eval_acc)\n","        pres.append(precision)\n","        recs.append(recall)\n","        aucs.append(auc)\n","        f1s.append(f1)\n","\n","        plot_metrics(losses, accs, pres, recs, aucs, f1s)\n","\n","        if eval_acc > top_acc:\n","            top_state = {\n","              'model_state_dict': model.state_dict(),\n","              'epoch': epoch,\n","              'ep_loss': losses,\n","              'ep_acc': accs,\n","              'pres': pres,\n","              'recs': recs,\n","              'f1s': f1s,\n","              'aucs': aucs,\n","              'conf_matrix': conf_matrix\n","            }\n","            torch.save(top_state, pretrained_path + \"/max_\" + path)\n","        state = {\n","            'model_state_dict': model.state_dict(),\n","            'epoch': epoch,\n","            'ep_loss': losses,\n","            'ep_acc': accs,\n","            'pres': pres,\n","            'recs': recs,\n","            'f1s': f1s,\n","            'aucs': aucs,\n","            'conf_matrix': conf_matrix\n","        }\n","        torch.save(state, pretrained_path + \"/\" + path)"]},{"cell_type":"markdown","metadata":{"id":"ecvIuqbyFbRW"},"source":["设置参数并训练模型"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1PXTcWr9VjKowFpyiMdtH_ArJlOCQBA6_"},"executionInfo":{"elapsed":18737615,"status":"ok","timestamp":1715376854286,"user":{"displayName":"Seventhree","userId":"06810280268935198942"},"user_tz":-480},"id":"9YsohpWmFbya","outputId":"7578afe8-4fca-4200-873f-51d4c1e45541"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["import torch\n","from torch import nn\n","from torchsummary import summary\n","\n","def main():\n","    learning_rate = 8.1e-5\n","    batch_size = 128\n","    epochs = 30\n","    dropout_rate = 0.5\n","    d_model = 32\n","    heads = 8\n","    N = 6\n","    trg_vocab = 2\n","\n","    train_data, val_data = load_data()\n","\n","    train_loader = get_data_loader(train_data, batch_size)\n","    val_loader = get_data_loader(val_data, batch_size)\n","\n","    model = Transformer(trg_vocab, d_model, N, heads, dropout_rate)\n","    save_path = \"pretrained.pt\"\n","\n","    for p in model.parameters():\n","        if p.dim() > 1:\n","            nn.init.xavier_uniform_(p)\n","    model = model.to(\"cuda:0\")\n","    summary(model, (10, ))\n","\n","    optim = torch.optim.RAdam(model.parameters(), lr=learning_rate)\n","\n","    train_model(model, optim, epochs, train_loader, val_loader, save_path)\n","\n","main()"]},{"cell_type":"markdown","metadata":{"id":"axiQg6_02Qu9"},"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}